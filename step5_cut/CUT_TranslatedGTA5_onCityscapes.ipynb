{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojnBFr56JBTF","outputId":"fb079b77-e1d6-4ff2-c1b7-181367e64ea1","executionInfo":{"status":"ok","timestamp":1750786991554,"user_tz":-120,"elapsed":25170,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7nk4MVzI8NP","outputId":"7c52a552-6bb3-46f8-9048-375657cf6aea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}],"source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/step5_cut/GTA5_translated.zip'\n","extract_path = '/content/dataset'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/Cityscapes.zip'\n","extract_path = '/content/dataset'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbEndFIMUYOv","outputId":"979646bf-73c8-4fef-a641-55cdc78a683b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/MLDL_repo/step5_cut')"],"metadata":{"id":"Vdc56KZnBDwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U fvcore"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8liFsqBJTS4","outputId":"620c26e8-6214-45df-8bbb-aaa6c224bd5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.13.2)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=af775e6c020e04bd9ea883c15c98b980db1a458025179b9155a90940b5410c8e\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=423a624b4011816fda6e9cffbce117d7e390d834e98bd17fcd80693cd006a06f\n","  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["import re\n","import os\n","import re\n","\n","def find_latest_checkpoint(checkpoint_dir):\n","    if not os.path.exists(checkpoint_dir):\n","        print(f\"Checkpoint directory {checkpoint_dir} does not exist.\")\n","        return None\n","\n","    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"bisenet_epoch_\") and f.endswith(\".pt\")]\n","    if not checkpoints:\n","        print(f\"No checkpoints found in {checkpoint_dir}.\")\n","        return None\n","\n","    # Extract epoch number from filename\n","    def extract_epoch(fname):\n","        match = re.search(r\"bisenet_epoch_(\\d+).pt\", fname)\n","        return int(match.group(1)) if match else -1\n","\n","    # Sort by epoch descending\n","    checkpoints.sort(key=extract_epoch, reverse=True)\n","\n","    latest = os.path.join(checkpoint_dir, checkpoints[0])\n","    print(f\" Found latest checkpoint: {latest}\")\n","    return latest\n"],"metadata":{"id":"1r9scjRjcJnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torchvision import transforms\n","\n","\n","def get_train_transform():\n","    return A.Compose([\n","        A.Resize(512, 1024),\n","        A.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","        ToTensorV2()\n","    ])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLtaoyzfaNGt","outputId":"63a50946-d786-4861-c482-99d0d8a4e974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","from torchvision import transforms as T\n","from PIL import Image\n","from datasets_custom.gta5_translated import GTA5\n","from models.bisenet.build_bisenet import BiSeNet\n","from train import train_one_epoch\n","\n","def main():\n","\n","\n","    dataset_root = '/content/dataset/GTA5_translated'\n","\n","    dataset_gta5 = GTA5(root=dataset_root, transform=get_train_transform())\n","    print(f\"Full dataset size: {len(dataset_gta5)}\")\n","\n","    train_loader = DataLoader(dataset_gta5, batch_size=2, shuffle=True, num_workers=2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    num_classes = 19\n","    base_lr = 2.5e-4\n","    batch_size = 2\n","    epochs = 50\n","    context_path = 'resnet18'\n","    checkpoint_dir = \"/content/drive/MyDrive/MLDL_repo/step5_cut/checkpoints_cut\"\n","\n","    if not os.path.exists(checkpoint_dir):\n","      os.makedirs(checkpoint_dir)\n","\n","    model = BiSeNet(num_classes=num_classes, context_path=context_path)\n","    if torch.cuda.device_count() > 1:\n","        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n","        model = nn.DataParallel(model)\n","\n","    model = model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    start_epoch = 0\n","    start_batch = 0\n","\n","    latest_ckpt = find_latest_checkpoint(checkpoint_dir)\n","    print(\"latest_ckpt is:\", latest_ckpt)\n","\n","    if latest_ckpt:\n","        print(f\"Restore from checkpoint: {latest_ckpt}\")\n","        checkpoint = torch.load(latest_ckpt, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        start_epoch = checkpoint['epoch'] + 1\n","        start_batch = 0  # Non serve più riprendere dal batch\n","        print(f\"Picking up from epoch {start_epoch}\")\n","    else:\n","        print(\"No checkpoint found, start training from scratch\")\n","\n","    # Check Data and Labels\n","    for images, labels in train_loader:\n","        print(\"Images shape:\", images.shape, \"dtype:\", images.dtype)\n","        print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)\n","        print(\"Unique labels:\", torch.unique(labels))\n","        break  # Print for the first batch only\n","\n","    # Training\n","    for epoch in range(start_epoch, epochs):\n","        current_start_batch = start_batch if epoch == start_epoch else 0\n","        train_one_epoch(model, train_loader, optimizer, base_lr, epoch, epochs, device,\n","                        checkpoint_dir=checkpoint_dir, start_batch=current_start_batch)\n","\n","\n","    final_model_path = \"/content/drive/MyDrive/MLDL_repo/step5_cut/final.pt\"\n","    torch.save(model.state_dict(), final_model_path)\n","    print(f\"Modello finale salvato in: {final_model_path}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"uMHyi1L09q3z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b14c558-3460-4ad3-d2ca-0e102b9125c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Full dataset size: 1750\n"," Found latest checkpoint: /content/drive/MyDrive/ML&DL/Progetto/MLDL_2025_main/MLDL_step5/checkpoints_2_2 (1)/bisenet_epoch_49.pt\n","latest_ckpt is: /content/drive/MyDrive/ML&DL/Progetto/MLDL_2025_main/MLDL_step5/checkpoints_2_2 (1)/bisenet_epoch_49.pt\n","Restore from checkpoint: /content/drive/MyDrive/ML&DL/Progetto/MLDL_2025_main/MLDL_step5/checkpoints_2_2 (1)/bisenet_epoch_49.pt\n","Picking up from epoch 50\n","Images shape: torch.Size([2, 3, 512, 1024]) dtype: torch.float32\n","Labels shape: torch.Size([2, 512, 1024]) dtype: torch.int64\n","Unique labels: tensor([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  13, 255])\n","Modello finale salvato in: /content/drive/MyDrive/ML&DL/Progetto/MLDL_2025_main/MLDL_step5/checkpoints_2_2 (1)/final.pt\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","from torchvision import transforms as T\n","from PIL import Image\n","from datasets_custom.gta5_aug import GTA5\n","from datasets_custom.cityscapes import CityScapes\n","from models.bisenet.build_bisenet import BiSeNet\n","from train import train_one_epoch\n","from train import validate\n","\n","\n","#initialize model\n","num_classes = 19\n","context_path = 'resnet18'\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = BiSeNet(num_classes=num_classes, context_path=context_path).to(device)\n","\n","\n","#load model\n","model_path = r\"/content/drive/MyDrive/MLDL_repo/step5_cut/final.pt\"\n","model.load_state_dict(torch.load(model_path, map_location='cpu'), strict = False )\n","\n","model.eval() #python built in function\n","\n","# Dataset definitions and transformation\n","transform = transforms.Compose([\n","        transforms.Resize((512, 1024)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","    ])\n","\n","target_transform = transforms.Compose([\n","        transforms.Resize((512, 1024), interpolation=transforms.InterpolationMode.NEAREST),\n","        transforms.PILToTensor()\n","    ])\n","\n","dataset_root = '/content/dataset/Cityscapes/Cityspaces'\n","\n","test_dataset = CityScapes(root=dataset_root, split='val', transform=transform, target_transform=target_transform)\n","print(f\"Test dataset size: {len(test_dataset)}\")\n","test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","\n","#results\n","best_miou, miou, per_class_ious = validate(model, test_loader, num_classes, device, best_miou=0.0)\n","print(\"\\n Risultati su Cityscape Validation:\")\n","print(f\" - mIoU: {miou:.4f}\")\n","for idx, iou in enumerate(per_class_ious):\n","        print(f\"Classe {idx}: IoU = {iou:.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2quVinH-JI6","outputId":"5f7db2cf-8ffd-4494-b246-51d1e274a227"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 500 images for split: val\n","Test dataset size: 500\n"]},{"output_type":"stream","name":"stderr","text":["🔍 Validating: 100%|██████████| 250/250 [00:30<00:00,  8.25it/s]"]},{"output_type":"stream","name":"stdout","text":[" Validation mIoU: 0.1029\n"," New best mIoU found!\n","\n"," Risultati su Cityscape Validation:\n"," - mIoU: 0.1029\n","Classe 0: IoU = 0.7073\n","Classe 1: IoU = 0.0304\n","Classe 2: IoU = 0.4479\n","Classe 3: IoU = 0.0217\n","Classe 4: IoU = 0.0002\n","Classe 5: IoU = 0.0062\n","Classe 6: IoU = 0.0035\n","Classe 7: IoU = 0.0001\n","Classe 8: IoU = 0.3398\n","Classe 9: IoU = 0.0525\n","Classe 10: IoU = 0.1978\n","Classe 11: IoU = 0.0003\n","Classe 12: IoU = 0.0008\n","Classe 13: IoU = 0.1251\n","Classe 14: IoU = 0.0102\n","Classe 15: IoU = 0.0123\n","Classe 16: IoU = 0.0000\n","Classe 17: IoU = 0.0000\n","Classe 18: IoU = 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}