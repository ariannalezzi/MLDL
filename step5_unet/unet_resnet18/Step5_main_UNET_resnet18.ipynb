{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5063,"status":"ok","timestamp":1749055163517,"user":{"displayName":"Arianna Lezzi","userId":"00779235871502967867"},"user_tz":-120},"id":"gN2FtF6yPPyb","outputId":"89ae134e-219c-4dcc-f77e-bce113e0404e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153937,"status":"ok","timestamp":1749055058682,"user":{"displayName":"Arianna Lezzi","userId":"00779235871502967867"},"user_tz":-120},"id":"u6PFUNExPUl9","outputId":"328991fe-884a-47e3-bb00-2e61ce6d2cf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}],"source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/GTA5.zip'\n","extract_path = '/content/dataset'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpV6d_FqPWdf"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/MLDL_repo/step5_unet/unet_resnet18')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_nEcN9QbJMj"},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","transform = A.Compose([\n","    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05, p=0.5),\n","    A.GaussianBlur(blur_limit=(3, 5), sigma_limit=(0.1, 1.0), p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.0, p=0.5),\n","    A.Resize(720, 1280),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1749055064656,"user":{"displayName":"Arianna Lezzi","userId":"00779235871502967867"},"user_tz":-120},"id":"KOJ-Qtcndr4W","outputId":"3a927112-4ec2-4cd8-b69d-f5cad49f18c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"]}],"source":["%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_eV24otb25e"},"outputs":[],"source":["import os\n","import re\n","\n","def find_latest_checkpoint(checkpoint_dir):\n","    if not os.path.exists(checkpoint_dir):\n","        print(f\"Checkpoint directory {checkpoint_dir} does not exist.\")\n","        return None\n","\n","    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"unet_epoch\") and f.endswith(\".pt\")]\n","    if not checkpoints:\n","        print(f\"No checkpoints found in {checkpoint_dir}.\")\n","        return None\n","\n","    def extract_epoch(fname):\n","        match = re.search(r\"unet_epoch_(\\d+)\\.pt\", fname)\n","        return int(match.group(1)) if match else -1\n","\n","    checkpoints.sort(key=lambda x: extract_epoch(x), reverse=True)\n","    latest = checkpoints[0]\n","    print(f\"The latest checkpoint is: {latest}\")\n","    return os.path.join(checkpoint_dir, latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nGJHWBmWNq7c","outputId":"5c58c6c7-453b-4c18-bc98-5523cea79618"},"outputs":[],"source":["### UNET - ENCODER RESNET 18\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","import time\n","import csv\n","import os\n","from model.resnet_unet import SResUnet\n","from torchvision.models import resnet18\n","from dataset_custom.gta5_aug import GTA5\n","from train import train, evaluate\n","from torch.utils.data import DataLoader, random_split\n","from dataset_custom.labels import GTA5Labels_TaskCV2017\n","from utils_p import show_predictions_triplet\n","\n","\n","def main():\n","\n","    # Parameters\n","    epochs = 30\n","    batch_size = 2\n","    lr = 1e-3\n","    num_classes = 19\n","    data_root = '/content/dataset/GTA5'\n","    checkpoint_dir = \"/content/drive/MyDrive/checkpoints_unet_resnet18/\"\n","\n","    if not os.path.exists(checkpoint_dir):\n","      os.makedirs(checkpoint_dir)\n","\n","    # Device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Dataset\n","    dataset = GTA5(root=data_root, transform=transform)\n","    n_total = len(dataset)\n","    train_len = int(n_total * 0.7) # 70% training\n","    val_len = n_total - train_len\n","    train_set, val_set = random_split(dataset, [train_len, val_len])\n","\n","    print(f\"Train dataset size: {len(train_set)}\")\n","    print(f\"Val dataset size: {len(val_set)}\")\n","\n","    # Dataloaders\n","    loader_args = dict(batch_size=batch_size, num_workers=2, pin_memory=True)\n","    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n","    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n","\n","    # Model\n","    model = SResUnet(resnet18, pretrained=True, out_channels=num_classes)\n","    model.to(device)\n","\n","    # Loss & Optimizer\n","    criterion = nn.CrossEntropyLoss(ignore_index=255)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    start_epoch = 0\n","    start_batch = 0\n","\n","    latest_ckpt = find_latest_checkpoint(checkpoint_dir)\n","    print(\"latest_ckpt is:\", latest_ckpt)\n","\n","    if latest_ckpt:\n","      print(f\"Restore from checkpoint: {latest_ckpt}\")\n","      checkpoint = torch.load(latest_ckpt, map_location=device)\n","      model.load_state_dict(checkpoint['model_state_dict'])\n","      # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","      start_epoch = checkpoint['epoch'] + 1  # Riparti dall'epoca successiva\n","      start_batch = 0  # Non serve pi√π riprendere dal batch\n","      print(f\"Picking up from epoch {start_epoch}\")\n","    else:\n","      print(\"No checkpoint found, start training from scratch\")\n","\n","    gta5_labels = GTA5Labels_TaskCV2017\n","\n","    log_file = f\"unet_resnet18_log.csv\"\n","    with open(log_file, 'w', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['epoch', 'train_loss', 'val_loss', 'accuracy', 'mIoU', 'dice', 'time_sec', 'vram_MB'])\n","\n","\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","        start = time.time()\n","        train_loss = train(model, train_loader, optimizer, criterion, device)\n","\n","        # checkpoint\n","        checkpoint_path = os.path.join(checkpoint_dir, f\"unet_epoch_{epoch+1}.pt\")\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","        }, checkpoint_path)\n","        print(f\"Checkpoint stored: {checkpoint_path}\")\n","\n","\n","        val_loss, acc, miou, dice = evaluate(model, train_loader, criterion, device, num_classes)\n","        end = time.time()\n","\n","        # VRAM tracking\n","        vram = torch.cuda.max_memory_allocated() / 1e6 if torch.cuda.is_available() else 0\n","        torch.cuda.reset_peak_memory_stats()\n","\n","        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | mIoU: {miou:.4f} | Dice: {dice:.4f} | Time: {end - start:.2f}s | VRAM: {vram:.2f} MB\")\n","        print(\"Visualization of 10 random samples:\")\n","        show_predictions_triplet(model, train_loader, device, gta5_labels, num_images=5, denorm=None)\n","\n","        with open(log_file, 'a', newline='') as f:\n","            writer = csv.writer(f)\n","            writer.writerow([epoch+1, train_loss, val_loss, acc, miou, dice, end - start, vram])\n","\n","\n","    final_model_path = \"/content/drive/MyDrive/MLDL_repo/step5_unet/unet_resnet18/unet_resnet18_final.pht\"\n","    torch.save(model.state_dict(), final_model_path)\n","    print(f\"Final Model Stored in: {final_model_path}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}