{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16541,"status":"ok","timestamp":1750698915429,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"},"user_tz":-120},"id":"Z2khd6YputgT","outputId":"63675892-3a82-43c1-bf8c-b01af2bcd6bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125444,"status":"ok","timestamp":1746784002209,"user":{"displayName":"Alessandro Ciarrocchi","userId":"04079237196958440021"},"user_tz":-120},"id":"3cBaGp8lwDZu","outputId":"45275759-cd69-4a29-efcd-8f611663a545"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}],"source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/GTA5.zip'\n","extract_path = '/content/dataset'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/Cityscapes.zip'\n","extract_path = '/content/cityscapes'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qS6j5BGtyDT0","executionInfo":{"status":"ok","timestamp":1750698990866,"user_tz":-120,"elapsed":75433,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}},"outputId":"1915cd39-9561-4cc0-8b6a-a23a77eed49f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DN7rBzgRUwgy","executionInfo":{"status":"ok","timestamp":1750698990869,"user_tz":-120,"elapsed":16,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/MLDL_repo/step3b')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10713,"status":"ok","timestamp":1750699001576,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"},"user_tz":-120},"id":"CLzIVnQCU1Tz","outputId":"881e5e93-b9da-499d-8ee0-3ef80e6f410d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=daa79eb7e294d092790e02edda605439b02da58a4446d6745dd31cba25b320dc\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=6b54977a94f2aa58e2f8bb4eed52daa6bf292d7125855e72fc5d0b906bbd0d5c\n","  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"]}],"source":["!pip install -U fvcore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwJ7opsfU2H5"},"outputs":[],"source":["import re\n","import os\n","import re\n","\n","def find_latest_checkpoint(checkpoint_dir):\n","    if not os.path.exists(checkpoint_dir):\n","        print(f\"Checkpoint directory {checkpoint_dir} does not exist.\")\n","        return None\n","\n","    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"bisenet_epoch_\") and f.endswith(\".pt\")]\n","    if not checkpoints:\n","        print(f\"No checkpoints found in {checkpoint_dir}.\")\n","        return None\n","\n","    def extract_epoch(fname):\n","        match = re.search(r\"bisenet_epoch_(\\d+).pt\", fname)\n","        return int(match.group(1)) if match else -1\n","\n","    checkpoints.sort(key=extract_epoch, reverse=True)\n","\n","    latest = os.path.join(checkpoint_dir, checkpoints[0])\n","    print(f\" Found latest checkpoint: {latest}\")\n","    return latest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbrqW_5dwVRN"},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","def get_train_transform():\n","    return A.Compose([\n","        A.MotionBlur(blur_limit=7, p=0.5),\n","        A.Resize(720, 1280),\n","        A.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","        ToTensorV2()\n","    ])\n","\n","def get_val_transform():\n","    return A.Compose([\n","        A.Resize(720, 1280),\n","        A.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","        ToTensorV2()\n","    ])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJXw-opUWv3D","outputId":"e16970b7-7ba8-45eb-d9fb-91fe5112a708","executionInfo":{"status":"ok","timestamp":1746351824237,"user_tz":-120,"elapsed":120607,"user":{"displayName":"Alessandro Ciarrocchi","userId":"04079237196958440021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset size: 1750\n","Val dataset size: 750\n","latest_ckpt is: /content/drive/MyDrive/checkpoints_3b/bisenet_epoch_49.pt\n","Restore from checkpoint: /content/drive/MyDrive/checkpoints_3b/bisenet_epoch_49.pt\n","Picking up from epoch 50\n","Images shape: torch.Size([2, 3, 720, 1280]) dtype: torch.float32\n","Labels shape: torch.Size([2, 720, 1280]) dtype: torch.uint8\n","Unique labels: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,\n","         16, 255], dtype=torch.uint8)\n","Modello finale salvato in: /content/drive/MyDrive/checkpoints_3b/bisenet_final_3b.pt\n"]},{"output_type":"stream","name":"stderr","text":["üîç Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [01:55<00:00,  3.23it/s]"]},{"output_type":"stream","name":"stdout","text":[" Validation mIoU: 0.6536\n"," New best mIoU found!\n","\n"," Results on GTA-V Validation:\n"," - mIoU: 0.6536\n","Class 0: IoU = 0.9822\n","Class 1: IoU = 0.8100\n","Class 2: IoU = 0.8489\n","Class 3: IoU = 0.6589\n","Class 4: IoU = 0.3763\n","Class 5: IoU = 0.7078\n","Class 6: IoU = 0.5214\n","Class 7: IoU = 0.5648\n","Class 8: IoU = 0.8186\n","Class 9: IoU = 0.7592\n","Class 10: IoU = 0.9555\n","Class 11: IoU = 0.4527\n","Class 12: IoU = 0.4089\n","Class 13: IoU = 0.8553\n","Class 14: IoU = 0.7426\n","Class 15: IoU = 0.7150\n","Class 16: IoU = 0.7127\n","Class 17: IoU = 0.4886\n","Class 18: IoU = 0.0384\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","from torchvision import transforms as T\n","from PIL import Image\n","from datasets.gta5_aug import GTA5\n","from models.bisenet.build_bisenet import BiSeNet\n","from train import train_one_epoch\n","from train import validate\n","\n","def main():\n","\n","    dataset_root = '/content/dataset/GTA5'\n","\n","    # Create the full dataset without transforms first\n","    full_dataset = GTA5(root=dataset_root,transform=None)\n","\n","    # Then split\n","    indices = list(range(len(full_dataset)))\n","    train_indices, val_indices = train_test_split(indices, test_size=0.30, random_state=42)\n","\n","    # Create two GTA5 datasets with different transforms\n","    train_dataset = GTA5(root=dataset_root, transform=get_train_transform())\n","    val_dataset = GTA5(root=dataset_root, transform=get_val_transform())\n","\n","    # Subset the datasets\n","    train_dataset = Subset(train_dataset, train_indices)\n","    val_dataset = Subset(val_dataset, val_indices)\n","    print(f\"Train dataset size: {len(train_dataset)}\")\n","    print(f\"Val dataset size: {len(val_dataset)}\")\n","\n","    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    num_classes = 19\n","    base_lr = 2.5e-4\n","    batch_size = 2\n","    epochs = 50\n","    context_path = 'resnet18'\n","    checkpoint_dir = \"/content/drive/MyDrive/checkpoints_3b_MotionBlur\"\n","\n","    model = BiSeNet(num_classes=num_classes, context_path=context_path)\n","    if torch.cuda.device_count() > 1:\n","        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n","        model = nn.DataParallel(model)\n","\n","    model = model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    start_epoch = 0\n","    start_batch = 0\n","\n","    latest_ckpt = find_latest_checkpoint(checkpoint_dir)\n","    print(\"latest_ckpt is:\", latest_ckpt)\n","\n","    if latest_ckpt:\n","        print(f\"Restore from checkpoint: {latest_ckpt}\")\n","        checkpoint = torch.load(latest_ckpt, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        start_epoch = checkpoint['epoch'] + 1\n","        start_batch = 0\n","        print(f\"Picking up from epoch {start_epoch}\")\n","    else:\n","        print(\"No checkpoint found, start training from scratch\")\n","\n","    # Check Data and Labels\n","    for images, labels in train_loader:\n","        print(\"Images shape:\", images.shape, \"dtype:\", images.dtype)\n","        print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)\n","        print(\"Unique labels:\", torch.unique(labels))\n","        break  # Print for the first batch only\n","\n","    # Training\n","    for epoch in range(start_epoch, epochs):\n","        current_start_batch = start_batch if epoch == start_epoch else 0\n","        train_one_epoch(model, train_loader, optimizer, base_lr, epoch, epochs, device,\n","                        checkpoint_dir=checkpoint_dir, start_batch=current_start_batch)\n","\n","    final_model_path = \"/content/drive/MyDrive/checkpoints_3b/bisenet_final_3b.pt\"\n","    torch.save(model.state_dict(), final_model_path)\n","    print(f\"Modello finale salvato in: {final_model_path}\")\n","\n","    #Validation\n","    best_miou = 0.0\n","    best_miou, miou, per_class_ious = validate(model, val_loader, num_classes, device, best_miou)\n","    print(\"\\n Results on GTA-V Validation:\")\n","    print(f\" - mIoU: {miou:.4f}\")\n","    for idx, iou in enumerate(per_class_ious):\n","        print(f\"Class {idx}: IoU = {iou:.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from PIL import Image\n","from datasets_custom.gta5_aug import GTA5\n","from datasets_custom.cityscapes import CityScapes\n","from models.bisenet.build_bisenet import BiSeNet\n","from datasets_custom.labels import GTA5Labels_TaskCV2017\n","from train import validate\n","\n","\n","def main():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    num_classes = 19\n","    context_path = 'resnet18'\n","    batch_size = 2\n","\n","\n","    model = BiSeNet(num_classes=num_classes, context_path=context_path)\n","    model = model.to(device)\n","\n","\n","    final_model_path = \"/content/drive/MyDrive/MLDL_repo/step3b/final_models/bisenet_final_3b_MotionBlur.pt\"\n","    model.load_state_dict(torch.load(final_model_path, map_location=device))\n","    model.eval()\n","    print(f\"Model {final_model_path} has been upload\")\n","\n","    # Prepara il Cityscapes validation loader\n","    transform = transforms.Compose([\n","        transforms.Resize((512, 1024)),  # Cityscapes resolution\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ])\n","\n","    target_transform = transforms.Compose([\n","        transforms.Resize((512, 1024), interpolation=transforms.InterpolationMode.NEAREST),\n","        transforms.PILToTensor()\n","    ])\n","\n","    dataset_root = '/content/cityscapes/Cityscapes/Cityspaces'\n","\n","    val_dataset = CityScapes(\n","    root=dataset_root,\n","    split='val',\n","    transform=transform,\n","    target_transform=target_transform)\n","\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    # results\n","    best_miou, miou, per_class_ious = validate(model, val_loader, num_classes, device, best_miou=0.0)\n","    print(\"\\n Validation Results on Cityscape:\")\n","    print(f\" - mIoU: {miou:.4f}\")\n","    for idx, label in enumerate(GTA5Labels_TaskCV2017.list_):\n","        print(f\"{label.name:>15}: IoU = {per_class_ious[idx]:.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDO4dmKQubFD","executionInfo":{"status":"ok","timestamp":1750699085876,"user_tz":-120,"elapsed":83525,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}},"outputId":"94a0ffd9-48a5-4adf-f4e0-9e652b72e8b1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 149MB/s]\n","Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171M/171M [00:01<00:00, 131MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model /content/drive/MyDrive/MLDL_repo/step3b/final_models/bisenet_final_3b_MotionBlur.pt has been upload\n","Loaded 500 images for split: val\n"]},{"output_type":"stream","name":"stderr","text":["Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:56<00:00,  4.39it/s]"]},{"output_type":"stream","name":"stdout","text":[" Validation mIoU: 0.1871\n"," New best mIoU found!\n","\n"," Validation Results on Cityscape:\n"," - mIoU: 0.1871\n","           road: IoU = 0.3777\n","       sidewalk: IoU = 0.0634\n","       building: IoU = 0.5743\n","           wall: IoU = 0.0739\n","          fence: IoU = 0.0481\n","           pole: IoU = 0.0001\n","          light: IoU = 0.0062\n","           sign: IoU = 0.0020\n","     vegetation: IoU = 0.7605\n","        terrain: IoU = 0.0497\n","            sky: IoU = 0.6551\n","         person: IoU = 0.3795\n","          rider: IoU = 0.0683\n","            car: IoU = 0.4033\n","          truck: IoU = 0.0508\n","            bus: IoU = 0.0212\n","          train: IoU = 0.0046\n","      motocycle: IoU = 0.0159\n","        bicycle: IoU = 0.0007\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}