{"cells":[{"cell_type":"markdown","source":["loading datasets"],"metadata":{"id":"zBDQJHtk1Mj8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15628,"status":"ok","timestamp":1750696785011,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"},"user_tz":-120},"id":"Z2khd6YputgT","outputId":"99bc5986-67f9-4d43-842d-622a35981d1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cBaGp8lwDZu"},"outputs":[],"source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/GTA5.zip'\n","extract_path = '/content/dataset'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/MLDL_repo/Cityscapes.zip'\n","extract_path = '/content/cityscapes'\n","\n","os.makedirs(extract_path, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Extraction complete!\")"],"metadata":{"id":"aLmBjbEE1Q--","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750696894098,"user_tz":-120,"elapsed":109085,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}},"outputId":"9a7526f1-e024-42f0-93df-f4c76147a72b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN7rBzgRUwgy"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/MLDL_repo/step3b')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10409,"status":"ok","timestamp":1750697054690,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"},"user_tz":-120},"id":"CLzIVnQCU1Tz","outputId":"a95dc6ae-eed2-4b1f-fdf9-998006073262"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=657452c6cc1dab38d43734106e5860923d975d8f167beebf99416aa4bf955804\n","  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=86587c5421eb6560a4af3c61db80af8cb40da6f453cc44c3d635c5cffee95544\n","  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"]}],"source":["!pip install -U fvcore"]},{"cell_type":"markdown","source":["find checkpoint function"],"metadata":{"id":"Yi7WllxT1YDE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwJ7opsfU2H5"},"outputs":[],"source":["import re\n","import os\n","import re\n","\n","def find_latest_checkpoint(checkpoint_dir):\n","    if not os.path.exists(checkpoint_dir):\n","        print(f\"Checkpoint directory {checkpoint_dir} does not exist.\")\n","        return None\n","\n","    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"bisenet_epoch_\") and f.endswith(\".pt\")]\n","    if not checkpoints:\n","        print(f\"No checkpoints found in {checkpoint_dir}.\")\n","        return None\n","\n","    def extract_epoch(fname):\n","        match = re.search(r\"bisenet_epoch_(\\d+).pt\", fname)\n","        return int(match.group(1)) if match else -1\n","\n","    checkpoints.sort(key=extract_epoch, reverse=True)\n","\n","    latest = os.path.join(checkpoint_dir, checkpoints[0])\n","    print(f\" Found latest checkpoint: {latest}\")\n","    return latest\n"]},{"cell_type":"markdown","source":["data augmentations trasformation"],"metadata":{"id":"eKi_-Ruy1cUf"}},{"cell_type":"code","source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torchvision import transforms\n","\n","def get_train_transform():\n","    return A.Compose([\n","        A.GaussNoise(var_limit=(1.0, 5.0), p=0.5),\n","        A.Resize(720, 1280),\n","        A.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","        ToTensorV2()\n","    ])"],"metadata":{"id":"QRZ-p8CSn5ef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["main"],"metadata":{"id":"1_4b2gUT2Gvm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJXw-opUWv3D","outputId":"f58bcff4-fa0e-4cf4-b572-2b83fd0ef863","executionInfo":{"status":"ok","timestamp":1747140862858,"user_tz":-120,"elapsed":17821,"user":{"displayName":"Arianna Lezzi","userId":"13540662585303372006"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset size: 1750\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n","Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n","100%|██████████| 171M/171M [00:01<00:00, 149MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["The latest checkpoint is: bisenet_epoch_49.pt\n","latest_ckpt is: /content/drive/MyDrive/checkpoints_3b_GaussianNoise/bisenet_epoch_49.pt\n","Restore from checkpoint: /content/drive/MyDrive/checkpoints_3b_GaussianNoise/bisenet_epoch_49.pt\n","Picking up from epoch 50\n","Images shape: torch.Size([2, 3, 720, 1280]) dtype: torch.float32\n","Labels shape: torch.Size([2, 720, 1280]) dtype: torch.uint8\n","Unique labels: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,\n","         15,  16, 255], dtype=torch.uint8)\n","Modello finale salvato in: /content/drive/MyDrive/checkpoints_3b_GaussianNoise/bisenet_final_3b_GaussianNoise.pht\n"]}],"source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","from torchvision import transforms as T\n","from PIL import Image\n","from datasets_custom.gta5_aug import GTA5\n","from models.bisenet.build_bisenet import BiSeNet\n","from train import train_one_epoch\n","from train import validate\n","\n","def main():\n","\n","    dataset_root = '/content/dataset/GTA5'\n","\n","    # Create the full dataset without transforms first\n","    full_dataset = GTA5(root=dataset_root, transform=None)\n","\n","    # Then split\n","    indices = list(range(len(full_dataset)))\n","    train_indices, val_indices = train_test_split(indices, test_size=0.30, random_state=42)\n","\n","    # Create two GTA5 datasets with different transforms\n","    train_dataset = GTA5(root=dataset_root, transform=get_train_transform())\n","\n","    # Subset the datasets\n","    train_dataset = Subset(train_dataset, train_indices)\n","    print(f\"Train dataset size: {len(train_dataset)}\")\n","\n","\n","    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    num_classes = 19\n","    base_lr = 2.5e-4\n","    batch_size = 2\n","    epochs = 50\n","    context_path = 'resnet18'\n","    checkpoint_dir = \"/content/drive/MyDrive/checkpoints_3b_GaussianNoise\"\n","\n","    if not os.path.exists(checkpoint_dir):\n","      os.makedirs(checkpoint_dir)\n","\n","    model = BiSeNet(num_classes=num_classes, context_path=context_path)\n","    if torch.cuda.device_count() > 1:\n","        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n","        model = nn.DataParallel(model)\n","\n","    model = model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    start_epoch = 0\n","    start_batch = 0\n","\n","    latest_ckpt = find_latest_checkpoint(checkpoint_dir)\n","    print(\"latest_ckpt is:\", latest_ckpt)\n","\n","    if latest_ckpt:\n","        print(f\"Restore from checkpoint: {latest_ckpt}\")\n","        checkpoint = torch.load(latest_ckpt, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        start_epoch = checkpoint['epoch'] + 1\n","        start_batch = 0\n","        print(f\"Picking up from epoch {start_epoch}\")\n","    else:\n","        print(\"No checkpoint found, start training from scratch\")\n","\n","    # Check Data and Labels\n","    for images, labels in train_loader:\n","        print(\"Images shape:\", images.shape, \"dtype:\", images.dtype)\n","        print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)\n","        print(\"Unique labels:\", torch.unique(labels))\n","        break  # Print for the first batch only\n","\n","    # Training\n","    for epoch in range(start_epoch, epochs):\n","        current_start_batch = start_batch if epoch == start_epoch else 0\n","        train_one_epoch(model, train_loader, optimizer, base_lr, epoch, epochs, device,\n","                        checkpoint_dir=checkpoint_dir, start_batch=current_start_batch)\n","\n","    final_model_path = \"/content/drive/MyDrive/MLDL_repo/step3b/final_models/bisenet_final_3b_GaussianNoise.pht\"\n","    torch.save(model.state_dict(), final_model_path)\n","    print(f\"Modello finale salvato in: {final_model_path}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","source":["import os\n","import torch\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","from torchvision import transforms as T\n","from PIL import Image\n","from datasets_custom.gta5_aug import GTA5\n","from datasets_custom.cityscapes import CityScapes\n","from models.bisenet.build_bisenet import BiSeNet\n","from datasets_custom.labels import GTA5Labels_TaskCV2017\n","from train import validate\n","\n","\n","#initialize model\n","num_classes = 19\n","context_path = 'resnet18'\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = BiSeNet(num_classes=num_classes, context_path=context_path).to(device)\n","\n","\n","# load model\n","model_path = r\"/content/drive/MyDrive/MLDL_repo/step3b/final_models/bisenet_final_3b_GaussianNoise.pht\"\n","model.load_state_dict(torch.load(model_path, map_location='cpu'), strict = False )\n","\n","model.eval() #python built in function\n","\n","# Dataset definitions and transformation\n","transform = transforms.Compose([\n","        transforms.Resize((512, 1024)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n","                    std=(0.229, 0.224, 0.225)),\n","    ])\n","\n","target_transform = transforms.Compose([\n","        transforms.Resize((512, 1024), interpolation=transforms.InterpolationMode.NEAREST),\n","        transforms.PILToTensor()\n","    ])\n","\n","dataset_root = '/content/cityscapes/Cityscapes/Cityspaces'\n","\n","test_dataset = CityScapes(root=dataset_root, split='val', transform=transform, target_transform=target_transform)\n","print(f\"Test dataset size: {len(test_dataset)}\")\n","test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","\n","# results\n","best_miou, miou, per_class_ious = validate(model, test_loader, num_classes, device, best_miou=0.0)\n","print(\"\\n Validation Results on Cityscape:\")\n","print(f\" - mIoU: {miou:.4f}\")\n","for idx, label in enumerate(GTA5Labels_TaskCV2017.list_):\n","    print(f\"{label.name:>15}: IoU = {per_class_ious[idx]:.4f}\")"],"metadata":{"id":"bFK7gL9Wo2IS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750697332261,"user_tz":-120,"elapsed":60868,"user":{"displayName":"MLDL_2025","userId":"06522763633669336238"}},"outputId":"7a39406a-053a-487b-832c-2fe782437ea0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 500 images for split: val\n","Test dataset size: 500\n"]},{"output_type":"stream","name":"stderr","text":["Validating: 100%|██████████| 250/250 [00:57<00:00,  4.37it/s]"]},{"output_type":"stream","name":"stdout","text":[" Validation mIoU: 0.1603\n"," New best mIoU found!\n","\n"," Validation Results on Cityscape:\n"," - mIoU: 0.1603\n","           road: IoU = 0.1768\n","       sidewalk: IoU = 0.0870\n","       building: IoU = 0.5970\n","           wall: IoU = 0.0193\n","          fence: IoU = 0.0059\n","           pole: IoU = 0.0000\n","          light: IoU = 0.0072\n","           sign: IoU = 0.0046\n","     vegetation: IoU = 0.6596\n","        terrain: IoU = 0.0297\n","            sky: IoU = 0.7163\n","         person: IoU = 0.2264\n","          rider: IoU = 0.0007\n","            car: IoU = 0.4177\n","          truck: IoU = 0.0348\n","            bus: IoU = 0.0080\n","          train: IoU = 0.0000\n","      motocycle: IoU = 0.0529\n","        bicycle: IoU = 0.0010\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}